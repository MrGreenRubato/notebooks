{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification with sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X] downloading data...\n"
     ]
    }
   ],
   "source": [
    "print(\"[X] downloading data...\")\n",
    "mnist = datasets.fetch_mldata(\"MNIST Original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size : (59500, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "#Temporarily reduce the training set to speed up execution while testing...\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size = 0.15)\n",
    "print('X_train size :', X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept = [-0.0028118]\n",
      "intercept = [-0.0028118]\n",
      "*** LR ALL ***\n",
      "lr_all[0] = [-0.0028118]\n",
      "Score on training set :  0.993630252101\n",
      "Score on test set :  0.991904761905\n",
      "intercept = [-0.00042308]\n",
      "intercept = [-0.00042308]\n",
      "*** LR ALL ***\n",
      "lr_all[0] = [-0.0028118]\n",
      "lr_all[1] = [-0.00042308]\n",
      "Score on training set :  0.994218487395\n",
      "Score on test set :  0.990857142857\n",
      "intercept = [-0.00214818]\n",
      "intercept = [-0.00214818]\n",
      "*** LR ALL ***\n",
      "lr_all[0] = [-0.0028118]\n",
      "lr_all[1] = [-0.00042308]\n",
      "lr_all[2] = [-0.00214818]\n",
      "Score on training set :  0.982268907563\n",
      "Score on test set :  0.978380952381\n",
      "intercept = [-0.00360177]\n",
      "intercept = [-0.00360177]\n",
      "*** LR ALL ***\n",
      "lr_all[0] = [-0.0028118]\n",
      "lr_all[1] = [-0.00042308]\n",
      "lr_all[2] = [-0.00214818]\n",
      "lr_all[3] = [-0.00360177]\n",
      "Score on training set :  0.976588235294\n",
      "Score on test set :  0.972095238095\n",
      "intercept = [-0.00142595]\n",
      "intercept = [-0.00142595]\n",
      "*** LR ALL ***\n",
      "lr_all[0] = [-0.0028118]\n",
      "lr_all[1] = [-0.00042308]\n",
      "lr_all[2] = [-0.00214818]\n",
      "lr_all[3] = [-0.00360177]\n",
      "lr_all[4] = [-0.00142595]\n",
      "Score on training set :  0.986067226891\n",
      "Score on test set :  0.984476190476\n",
      "intercept = [ 0.00012678]\n",
      "intercept = [ 0.00012678]\n",
      "*** LR ALL ***\n",
      "lr_all[0] = [-0.0028118]\n",
      "lr_all[1] = [-0.00042308]\n",
      "lr_all[2] = [-0.00214818]\n",
      "lr_all[3] = [-0.00360177]\n",
      "lr_all[4] = [-0.00142595]\n",
      "lr_all[5] = [ 0.00012678]\n",
      "Score on training set :  0.977915966387\n",
      "Score on test set :  0.975142857143\n",
      "intercept = [-0.00269874]\n",
      "intercept = [-0.00269874]\n",
      "*** LR ALL ***\n",
      "lr_all[0] = [-0.0028118]\n",
      "lr_all[1] = [-0.00042308]\n",
      "lr_all[2] = [-0.00214818]\n",
      "lr_all[3] = [-0.00360177]\n",
      "lr_all[4] = [-0.00142595]\n",
      "lr_all[5] = [ 0.00012678]\n",
      "lr_all[6] = [-0.00269874]\n",
      "Score on training set :  0.988537815126\n",
      "Score on test set :  0.985523809524\n",
      "intercept = [-0.00067129]\n",
      "intercept = [-0.00067129]\n",
      "*** LR ALL ***\n",
      "lr_all[0] = [-0.0028118]\n",
      "lr_all[1] = [-0.00042308]\n",
      "lr_all[2] = [-0.00214818]\n",
      "lr_all[3] = [-0.00360177]\n",
      "lr_all[4] = [-0.00142595]\n",
      "lr_all[5] = [ 0.00012678]\n",
      "lr_all[6] = [-0.00269874]\n",
      "lr_all[7] = [-0.00067129]\n",
      "Score on training set :  0.986773109244\n",
      "Score on test set :  0.985333333333\n",
      "intercept = [-0.00405027]\n",
      "intercept = [-0.00405027]\n",
      "*** LR ALL ***\n",
      "lr_all[0] = [-0.0028118]\n",
      "lr_all[1] = [-0.00042308]\n",
      "lr_all[2] = [-0.00214818]\n",
      "lr_all[3] = [-0.00360177]\n",
      "lr_all[4] = [-0.00142595]\n",
      "lr_all[5] = [ 0.00012678]\n",
      "lr_all[6] = [-0.00269874]\n",
      "lr_all[7] = [-0.00067129]\n",
      "lr_all[8] = [-0.00405027]\n",
      "Score on training set :  0.951394957983\n",
      "Score on test set :  0.942666666667\n",
      "intercept = [-0.00173368]\n",
      "intercept = [-0.00173368]\n",
      "*** LR ALL ***\n",
      "lr_all[0] = [-0.0028118]\n",
      "lr_all[1] = [-0.00042308]\n",
      "lr_all[2] = [-0.00214818]\n",
      "lr_all[3] = [-0.00360177]\n",
      "lr_all[4] = [-0.00142595]\n",
      "lr_all[5] = [ 0.00012678]\n",
      "lr_all[6] = [-0.00269874]\n",
      "lr_all[7] = [-0.00067129]\n",
      "lr_all[8] = [-0.00405027]\n",
      "lr_all[9] = [-0.00173368]\n",
      "Score on training set :  0.962554621849\n",
      "Score on test set :  0.963523809524\n",
      "lr all[x] [-0.0028118]\n",
      "Test score for 0 : 0.991904761904762\n",
      "lr all[x] [-0.00042308]\n",
      "Test score for 1 : 0.9908571428571429\n",
      "lr all[x] [-0.00214818]\n",
      "Test score for 2 : 0.9783809523809524\n",
      "lr all[x] [-0.00360177]\n",
      "Test score for 3 : 0.9720952380952381\n",
      "lr all[x] [-0.00142595]\n",
      "Test score for 4 : 0.9844761904761905\n",
      "lr all[x] [ 0.00012678]\n",
      "Test score for 5 : 0.9751428571428571\n",
      "lr all[x] [-0.00269874]\n",
      "Test score for 6 : 0.9855238095238095\n",
      "lr all[x] [-0.00067129]\n",
      "Test score for 7 : 0.9853333333333333\n",
      "lr all[x] [-0.00405027]\n",
      "Test score for 8 : 0.9426666666666667\n",
      "lr all[x] [-0.00173368]\n",
      "Test score for 9 : 0.9635238095238096\n",
      "Mean performace on training set :  0.979994957983\n",
      "Mean performance on test set :  0.97699047619\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Lambda = 1\n",
    "\n",
    "#lr = LogisticRegression(solver='lbfgs', C=1/Lambda)  # C = 1/lambda (default = 1, if lower, regularization is stronger)\n",
    "\n",
    "test_scores_for_all = np.array([])\n",
    "train_scores_for_all = np.array([])\n",
    "\n",
    "lr_all = [0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "# One vs all algorithm\n",
    "for value in range(10):\n",
    "    y = np.copy(y_train)\n",
    "    y[y_train==value] = 1\n",
    "    y[y_train!=value] = 0\n",
    "\n",
    "    lr_all[value] = LogisticRegression(solver='lbfgs', C=1/Lambda)  # C = 1/lambda (default = 1, if lower, regularization is stronger)\n",
    "    lr_all[value].fit(X_train,y)\n",
    "    lr_all[value].get_params()\n",
    "\n",
    "    #print('Coeff = {}, intercept = {}'.format(lr.coef_[0], lr.intercept_ ))\n",
    "    print('intercept = {}'.format(lr_all[value].intercept_ ))\n",
    "    #lr_all = np.append(lr_all, np.copy(lr))\n",
    "    print('intercept = {}'.format(lr_all[value].intercept_ ))\n",
    "    print('*** LR ALL ***')\n",
    "    for i in range(value+1):\n",
    "        print('lr_all[{}] = {}'.format(i, lr_all[i].intercept_))\n",
    "    \n",
    "    train_score = lr_all[value].score(X_train, y)\n",
    "    train_scores_for_all = np.append(train_scores_for_all, train_score)\n",
    "    print('Score on training set : ', lr_all[value].score(X_train,y))\n",
    "    \n",
    "    y_test_one = np.copy(y_test)\n",
    "    y_test_one[y_test==value] = 1\n",
    "    y_test_one[y_test!=value] = 0\n",
    " \n",
    "    test_score = lr_all[value].score(X_test,y_test_one)\n",
    "    test_scores_for_all = np.append(test_scores_for_all, test_score)\n",
    "    \n",
    "    print('Score on test set : ', test_score)\n",
    "\n",
    "for value in range(10):\n",
    "    print('lr all[x]', lr_all[value].intercept_)\n",
    "    print('Test score for {} : {}'.format(value, test_scores_for_all[value]))\n",
    "\n",
    "print('Mean performace on training set : ', np.mean(train_scores_for_all))\n",
    "print('Mean performance on test set : ', np.mean(test_scores_for_all))\n",
    "\n",
    "#Note: for 15% datatest, score for training set is 98% and test set : 97.5%\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total :  [1265 8735]\n",
      "perf = 87.35000000000001%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEACAYAAACj0I2EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEXxJREFUeJzt3X+MZWV9x/H3Z1mhIpFuVXYsiywGf4CJQVJWUzS5RkRs\nE5baBFETf9XWhFqITRp2+WenTROLiTYmLX9Yka4tFJDWgo3FhcCNsYkLCltWd8VtyS7Lyo6/tYSk\nWeTbP+6BDuvszp2duffuPPN+JTdz5rnnnO858+Nzz33Oec5NVSFJWv5WTXoDJElLw0CXpEYY6JLU\nCANdkhphoEtSIwx0SWrEvIGe5KQk25M8lGRnki1d+5ok25I8kuSrSU6dtczmJHuS7E5y8Sh3QJI0\nkGGuQ09yclU9leQE4D+Aq4DfB35cVZ9Mcg2wpqo2JTkXuAm4AFgH3AO8qrzgXZJGaqgul6p6qps8\nCVgNFLAR2Nq1bwUu66YvBW6pqqerai+wB9iwVBssSZrbUIGeZFWSh4CDwN1V9QCwtqpmAKrqIHBa\nN/vpwP5Zix/o2iRJIzTsEfozVfUGBl0oG5K8jsFR+vNmW+qNkyQNb/VCZq6qXyTpA5cAM0nWVtVM\nkingB91sB4AzZi22rmt7niS+AEjSMaiqzNU+zFUuL332CpYkLwTeDuwG7gQ+2M32AeCObvpO4Iok\nJyY5CzgbuP8IGzWRx5YtW1ZUXffZuq3WXon7fDTDHKG/HNiaZBWDF4Bbq+orSb4B3Jbkw8A+4PIu\npHcluQ3YBRwCrqz5tkKStGjzBnpV7QTOn6P9J8BFR1jmE8AnFr11kqShrciRor1eb0XVnWRt97n9\nupOsvRL3+WiGGlg0ksKJPTGStEBJqGM9KSpJWh4MdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQI\nA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQ\nJakRBrokNcJAl6RGGOiS1AgDXdJxY2pqPUlG9piaWj/pXRypVNVkCic1qdqSjk9JgFHmQljuuZOE\nqspcz3mELkmNmDfQk6xLcm+S7yTZmeRPuvYtSR5P8mD3uGTWMpuT7EmyO8nFo9wBSdLAvF0uSaaA\nqarakeQU4FvARuDdwP9U1acPm/8c4GbgAmAdcA/wqsP7V+xykXQ4u1zmt6gul6o6WFU7uukngd3A\n6c+ue45FNgK3VNXTVbUX2ANsOJYNlyQNb0F96EnWA+cB27umjyXZkeRzSU7t2k4H9s9a7AD//wIg\nSRqRoQO96265Hbi6O1K/HnhlVZ0HHAQ+NZpNlCQNY/UwMyVZzSDM/6Gq7gCoqh/OmuXvgC930weA\nM2Y9t65r+xXT09PPTfd6PXq93pCbLUkrQ7/fp9/vDzXvUNehJ/kC8KOq+tNZbVNVdbCb/jhwQVW9\nN8m5wE3AGxl0tdyNJ0UlDcGTovM72knReY/Qk1wIvA/YmeQhBj/ta4H3JjkPeAbYC3wUoKp2JbkN\n2AUcAq40uSVp9BwpKum44RH6/BwpKkkrgIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1Ij\nDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJA\nl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRswb6EnWJbk3yXeS7ExyVde+\nJsm2JI8k+WqSU2ctsznJniS7k1w8yh2QJA2kqo4+QzIFTFXVjiSnAN8CNgIfAn5cVZ9Mcg2wpqo2\nJTkXuAm4AFgH3AO8qg4rlOTwJkkrXBJglLkQlnvuJKGqMtdz8x6hV9XBqtrRTT8J7GYQ1BuBrd1s\nW4HLuulLgVuq6umq2gvsATYsag8kSfNaUB96kvXAecA3gLVVNQOD0AdO62Y7Hdg/a7EDXZskaYRW\nDztj191yO3B1VT2Z5PD3LQt+HzM9Pf3cdK/Xo9frLXQVktS0fr9Pv98fat55+9ABkqwG/g3496r6\nTNe2G+hV1UzXz35fVZ2TZBNQVXVdN99dwJaq2n7YOu1Dl/Q89qHPb1F96J3PA7ueDfPOncAHu+kP\nAHfMar8iyYlJzgLOBu5f8FZLkhZkmKtcLgS+Buxk8NJZwLUMQvo24AxgH3B5Vf2sW2Yz8AfAIQZd\nNNvmWK9H6JKexyP0+R3tCH2oLpdRMNAlHc5An99SdLlIko5zBrokNcJAl6RGGOiS1AgDXZIaYaBL\nUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1\nwkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1Ih5Az3JDUlmkjw8\nq21LkseTPNg9Lpn13OYke5LsTnLxqDZckvR8wxyh3wi8Y472T1fV+d3jLoAk5wCXA+cA7wSuT5Il\n21pJ0hHNG+hV9XXgp3M8NVdQbwRuqaqnq2ovsAfYsKgtlCQNZTF96B9LsiPJ55Kc2rWdDuyfNc+B\nrk2SNGKrj3G564G/qKpK8pfAp4CPLHQl09PTz033ej16vd4xbo4ktanf79Pv94eaN1U1/0zJmcCX\nq+r1R3suySagquq67rm7gC1VtX2O5WqY2pJWjsEpt1HmQljuuZOEqprz3OSwXS5hVp95kqlZz70L\n+HY3fSdwRZITk5wFnA3cv/BNliQt1LxdLkluBnrAS5I8BmwB3prkPOAZYC/wUYCq2pXkNmAXcAi4\n0sNwScvB1NR6Zmb2jWz9a9eeycGDe0e2fhiyy2Ukhe1ykXSYSXa5LJfunqXocpEkHecMdElqhIEu\nSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLU\nCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBro0j6mp9SQZ2WNqav2kd1GNyFJ8CvUxFU5qUrWlhVgu\nnwbfgkn+rJfL7zkJVZW5nvMIXZIaYaBrQex+kI5fdrloQZbL29KltBL3eVLschliLXa5SFL7DHRJ\naoSBLkmNmDfQk9yQZCbJw7Pa1iTZluSRJF9Ncuqs5zYn2ZNkd5KLR7XhkqTnG+YI/UbgHYe1bQLu\nqarXAPcCmwGSnAtcDpwDvBO4PoMzDZKkEZs30Kvq68BPD2veCGztprcCl3XTlwK3VNXTVbUX2ANs\nWJpNlSQdzbH2oZ9WVTMAVXUQOK1rPx3YP2u+A12bJGnEVi/Reo7p4srp6ennpnu9Hr1eb4k2R5La\n0O/36ff7Q8071MCiJGcCX66q13ff7wZ6VTWTZAq4r6rOSbIJqKq6rpvvLmBLVW2fY50OLFqGlsvg\ni6W0Evd5UhxYNMRalmBgUbrHs+4EPthNfwC4Y1b7FUlOTHIWcDZw/4K3WJK0YPN2uSS5GegBL0ny\nGLAF+Cvgi0k+DOxjcGULVbUryW3ALuAQcKWH4ZI0Ht7LRQuyXN6WLqWVuM+TYpfLEGvxXi6S1D4D\nXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNCX\noamp9SQZ6WNqav2kd1PSAnn73GVo9Lf5hCPd6nO53GJ0Ka3EfZ4Ub587xFq8fa4ktc9Al6RGGOiS\n1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6dJxyRLAWypGiy5AjRcdrUvs8yd/z1NR6Zmb2jazq\n2rVncvDg3l/dGkeKzr+Wo4wUNdCXIQN9vFZioLe7z20Hul0uktQIA12SGrF6MQsn2Qv8HHgGOFRV\nG5KsAW4FzgT2ApdX1c8XuZ2SpHks9gj9GaBXVW+oqg1d2ybgnqp6DXAvsHmRNSRJQ1hsoGeOdWwE\ntnbTW4HLFllDkjSExQZ6AXcneSDJR7q2tVU1A1BVB4HTFllD8ppsaQiL6kMHLqyqJ5K8DNiW5BF+\n9bqf4+saNC1Lg2uiR/unNDMz55Vg0rKxqECvqie6rz9M8q/ABmAmydqqmkkyBfzgSMtPT08/N93r\n9ej1eovZHElqTr/fp9/vDzXvMQ8sSnIysKqqnkzyImAb8OfA24CfVNV1Sa4B1lTVpjmWd2DRMXLA\nSWu13edJ15107QWt5SgDixZzhL4W+FKS6tZzU1VtS/JN4LYkHwb2AZcvooYkaUgO/V+GPHJrrbb7\nPOm6k669oLU49F+S2megS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0\nSWpEE4E+6g8/8IMPJC0HTdyca7ncVGepeNOm1mq7z5OuO+naC1qLN+eSpPYZ6JLUCANdkhphoEtS\nIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpESML9CSX\nJPluku8luWZUdSbJD9aQdDwZSaAnWQX8DfAO4HXAe5K8dhS1jk1/SdYyM7OPwQ3xh33ct6D5B+tf\nKv0lXNdyqDvJ2iut7iRrT6rupGvPbVRH6BuAPVW1r6oOAbcAG0dU6xj0V1jdSdaeVN1J1l5pdSdZ\ne1J1J117bqMK9NOB/bO+f7xrkySNiCdFJakRI/mQ6CRvAqar6pLu+01AVdV1s+Y5fj51WZKWkSN9\nSPSoAv0E4BHgbcATwP3Ae6pq95IXkyQBsHoUK62qXyb5GLCNQbfODYa5JI3WSI7QJUnjt6JOik5q\nsFOSG5LMJHl4XDW7uuuS3JvkO0l2JrlqjLVPSrI9yUNd7S3jqt3VX5XkwSR3jrnu3iT/2e33/WOs\ne2qSLybZ3f2+3ziGmq/u9vPB7uvPx/w39vEk307ycJKbkpw4prpXd3/TY/2fGkpVrYgHgxev/wLO\nBF4A7ABeO6babwbOAx4e8z5PAed106cwOK8xln3uap7cfT0B+AawYYy1Pw78I3DnmH/mjwJrxlmz\nq/v3wIe66dXAi8dcfxXwfeCMMdX7ze5nfWL3/a3A+8dQ93XAw8BJ3d/1NuCV4/59H+mxko7QJzbY\nqaq+Dvx0HLUOq3uwqnZ0008CuxnjeICqeqqbPIlByIylfy/JOuB3gM+No97h5RnzO98kLwbeUlU3\nAlTV01X1i3FuA3AR8N9VtX/eOZfOCcCLkqwGTmbwgjJq5wDbq+p/q+qXwNeAd42h7lBWUqCv6MFO\nSdYzeJewfYw1VyV5CDgI3F1VD4yp9F8Df8aYXkAOU8DdSR5I8odjqnkW8KMkN3bdH59N8sIx1X7W\nu4F/Glexqvo+8CngMeAA8LOqumcMpb8NvCXJmiQnMzhwOGMMdYeykgJ9xUpyCnA7cHV3pD4WVfVM\nVb0BWAe8Mcm5o66Z5HeBme6dSbrHOF1YVecz+Ef/4yRvHkPN1cD5wN92tZ8CNo2hLgBJXgBcCnxx\njDV/ncE77DMZdL+ckuS9o65bVd8FrgPuBr4CPAT8ctR1h7WSAv0A8IpZ36/r2prWvR29HfiHqrpj\nEtvQvf2/D7hkDOUuBC5N8iiDI8a3JvnCGOoCUFVPdF9/CHyJQVffqD0O7K+qb3bf384g4MflncC3\nun0el4uAR6vqJ13Xx78Avz2OwlV1Y1X9VlX1gJ8B3xtH3WGspEB/ADg7yZnd2fArgHFeATGJo0WA\nzwO7quoz4yya5KVJTu2mXwi8HfjuqOtW1bVV9YqqeiWD3/G9VfX+UdcFSHJy926IJC8CLmbwFn2k\nqmoG2J/k1V3T24Bdo647y3sYY3dL5zHgTUl+LUkY7PNYxrokeVn39RXA7wE3j6PuMEYysOh4VBMc\n7JTkZqAHvCTJY8CWZ09gjbjuhcD7gJ1dX3YB11bVXaOuDbwc2NrdSnkVcGtVfWUMdSdpLfCl7rYW\nq4GbqmrbmGpfBdzUdX88CnxoHEW7fuSLgD8aR71nVdX9SW5n0OVxqPv62TGV/+ckv9HVvXICJ6CP\nyIFFktSIldTlIklNM9AlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWrE/wEHEef2I/rGCAAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e146b1f710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 has been missed 260 times\n",
      "9 has been missed 146 times\n",
      "5 has been missed 117 times\n",
      "3 has been missed 113 times\n",
      "2 has been missed 76 times\n",
      "6 has been missed 63 times\n",
      "7 has been missed 62 times\n",
      "4 has been missed 52 times\n",
      "0 has been missed 29 times\n",
      "1 has been missed 7 times\n",
      "Confusion :\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEACAYAAACnJV25AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmP8PnKZlrHMyJCQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e147b938d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getRandomDigitFrom(n):\n",
    "    r = np.random.randint(0,1000)\n",
    "    img = mnist.data[3000+n*6000+r].reshape(28,28)    \n",
    "    return img\n",
    "\n",
    "guesses = np.array([])\n",
    "confusion = np.empty((0,2))\n",
    "not_found = np.array([])\n",
    "\n",
    "for ntest in range(10000):\n",
    "    digit_to_guess = np.random.randint(0,10)\n",
    "    img = getRandomDigitFrom(digit_to_guess)\n",
    "    #plt.axis('off')\n",
    "    #plt.imshow(img,cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    #plt.show()\n",
    "    img = img.reshape(1,-1)\n",
    "    guessed = 0\n",
    "    wrong_digit = -1\n",
    "    #print('This is a ', digit_to_guess)\n",
    "    for i in range(len(lr_all)):\n",
    "        test = lr_all[i].predict(img) \n",
    "\n",
    "        if test:\n",
    "            #print('I guess this is a ', i)\n",
    "            if ( digit_to_guess == i):\n",
    "                #print('GUESSED !!!')\n",
    "                guessed = 1\n",
    "            else:\n",
    "                wrong_digit = i\n",
    "    \n",
    "    guesses = np.append(guesses, guessed)\n",
    "    if(guessed == 0):\n",
    "        if wrong_digit >= 0:\n",
    "            conf = np.sort(np.array([digit_to_guess, wrong_digit]))\n",
    "            confusion = np.vstack((confusion, conf))\n",
    "        else:\n",
    "            not_found = np.append(not_found,digit_to_guess)\n",
    "        \n",
    "       \n",
    "    \n",
    "w,d = np.unique(guesses, return_inverse=True)\n",
    "#print('confusion: ', confusion)\n",
    "#print('d', d)\n",
    "print('total : ', np.bincount(d))\n",
    "print('perf = {}%'.format(np.bincount(d)[1] / (np.bincount(d)[0] + np.bincount(d)[1]) *100))\n",
    "\n",
    "# Stats on most not found digits:\n",
    "not_found_qty = np.bincount(list(not_found))\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(range(10), not_found_qty, align='center')\n",
    "plt.xlim(-1,10)\n",
    "ax.set_xticks(range(10))\n",
    "plt.show()\n",
    "\n",
    "not_found_idx = np.ma.argsort(not_found_qty)[::-1]\n",
    "for i in range(not_found_idx.size):\n",
    "    print('{} has been missed {} times'.format(not_found_idx[i], not_found_qty[not_found_idx[i]]))\n",
    "\n",
    "\n",
    "#Stats on confusion:\n",
    "print('Confusion :')\n",
    "plt.scatter(confusion[:,0], confusion[:,1], alpha=0.01)\n",
    "plt.scatter(confusion[:,1], confusion[:,0], alpha=0.01)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## Better than using logistic regression, use SVM / SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "classifier = svm.SVC(C=100, gamma=0.001, kernel='linear' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "guesses = np.array([])\n",
    "confusion = np.empty((0,2))\n",
    "not_found = np.array([])\n",
    "\n",
    "for ntest in range(500):\n",
    "    digit_to_guess = np.random.randint(0,10)\n",
    "    img = getRandomDigitFrom(digit_to_guess)\n",
    "    #plt.axis('off')\n",
    "    #plt.imshow(img,cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    #plt.show()\n",
    "    img = img.reshape(1,-1)\n",
    "    guessed = 0\n",
    "    wrong_digit = -1\n",
    "    #print('This is a ', digit_to_guess)\n",
    "    test = classifier.predict(img)\n",
    "\n",
    "    #print('guessed : ', test)\n",
    "    if test == digit_to_guess:\n",
    "        guessed = 1\n",
    "    else:\n",
    "        wrong_digit = test\n",
    "    \n",
    "    guesses = np.append(guesses, guessed)\n",
    "    if(guessed == 0):\n",
    "        if wrong_digit >= 0:\n",
    "            conf = np.sort(np.array([digit_to_guess, wrong_digit]))\n",
    "            confusion = np.vstack((confusion, conf))\n",
    "        else:\n",
    "            not_found = np.append(not_found,digit_to_guess)\n",
    "        \n",
    "       \n",
    "    \n",
    "w,d = np.unique(guesses, return_inverse=True)\n",
    "#print('confusion: ', confusion)\n",
    "#print('d', d)\n",
    "print('total : ', np.bincount(d))\n",
    "print(np.bincount(d))\n",
    "if np.bincount(d).size == 1:\n",
    "    print('perf = 100%')\n",
    "else:\n",
    "    print('perf = {}%'.format(np.bincount(d)[1] / (np.bincount(d)[0] + np.bincount(d)[1]) *100))\n",
    "\n",
    "# Stats on most not found digits:\n",
    "not_found_qty = np.bincount(list(not_found))\n",
    "#print('not found qty',not_found_qty)\n",
    "\n",
    "if not_found_qty.size > 0:\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.bar(range(10), not_found_qty, align='center')\n",
    "    plt.xlim(-1,10)\n",
    "    ax.set_xticks(range(10))\n",
    "    plt.show()\n",
    "\n",
    "not_found_idx = np.ma.argsort(not_found_qty)[::-1]\n",
    "#print('not found index',not_found_idx)\n",
    "for i in range(not_found_idx.size):\n",
    "    print('{} has been missed {} times'.format(not_found_idx[i], not_found_qty[not_found_idx[i]]))\n",
    "\n",
    "\n",
    "#Stats on confusion:\n",
    "print('Confusion :')\n",
    "plt.scatter(confusion[:,0], confusion[:,1], alpha=0.05)\n",
    "plt.scatter(confusion[:,1], confusion[:,0], alpha=0.05)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
